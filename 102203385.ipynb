{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXYvBkFIFx3hu6vdTYbzFs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garimaahuja112/Topsis-for-Pretrained-Models-Garima-102203385/blob/main/102203385.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_RUeP-8bM0s",
        "outputId": "88b48630-f2b5-4c16-9598-e3f71a85a6f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=7a3c519a9ec34cfecc8c967128263b3160fe357a93ecc5ef50d4e67681040efe\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers evaluate rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from evaluate import load"
      ],
      "metadata": {
        "id": "EOz3xZ1-ew_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
        "\n",
        "# Select multiple texts\n",
        "num_samples = 5\n",
        "sample_texts = [dataset[i][\"article\"] for i in range(num_samples)]"
      ],
      "metadata": {
        "id": "3n7QO5qxfJ7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of pre-trained models\n",
        "models = [\n",
        "    \"facebook/bart-large-cnn\",\n",
        "    \"google/pegasus-cnn_dailymail\",\n",
        "    \"t5-small\",\n",
        "    \"t5-base\",\n",
        "    \"t5-large\"\n",
        "]"
      ],
      "metadata": {
        "id": "g_z7YEQYfU9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ROUGE evaluator\n",
        "rouge = load(\"rouge\")"
      ],
      "metadata": {
        "id": "yCKAXJ2qfgj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate a model on a single text\n",
        "def evaluate_model_on_text(model_name, text, reference_summary):\n",
        "    device = torch.device('cpu')\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "    # Initialize the summarizer pipeline with model and tokenizer\n",
        "    summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, framework=\"pt\", device=-1)\n",
        "\n",
        "    # Timing (in ms) for inference on CPU\n",
        "    start_time = time.time()\n",
        "    summary = summarizer(text, max_length=150, min_length=50, do_sample=False)\n",
        "    end_time = time.time()\n",
        "\n",
        "    inference_time = (end_time - start_time) * 1000\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    rouge_scores = rouge.compute(predictions=[summary[0]['summary_text']], references=[reference_summary])\n",
        "\n",
        "    # Calculate model size (in MB)\n",
        "    model_size = sum(p.numel() for p in model.parameters()) * 4 / (1024 ** 2)\n",
        "\n",
        "    return [\n",
        "        rouge_scores[\"rouge1\"],\n",
        "        rouge_scores[\"rouge2\"],\n",
        "        rouge_scores[\"rougeL\"],\n",
        "        inference_time,\n",
        "        model_size\n",
        "    ]"
      ],
      "metadata": {
        "id": "niw1ycaTgQbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topsis(decision_matrix, weights, benefit_criteria):\n",
        "    # Normalize the decision matrix\n",
        "    norm_matrix = decision_matrix / np.linalg.norm(decision_matrix, axis=0)\n",
        "\n",
        "    # Apply weights\n",
        "    weighted_matrix = norm_matrix * weights\n",
        "\n",
        "    # Compute ideal best and worst solutions based on benefit/penalty criteria\n",
        "    ideal_best = np.where(benefit_criteria, np.max(weighted_matrix, axis=0), np.min(weighted_matrix, axis=0))\n",
        "    ideal_worst = np.where(benefit_criteria, np.min(weighted_matrix, axis=0), np.max(weighted_matrix, axis=0))\n",
        "\n",
        "    # Calculate distances to ideal best and worst\n",
        "    distance_best = np.linalg.norm(weighted_matrix - ideal_best, axis=1)\n",
        "    distance_worst = np.linalg.norm(weighted_matrix - ideal_worst, axis=1)\n",
        "\n",
        "    # Calculate TOPSIS scores\n",
        "    topsis_scores = distance_worst / (distance_best + distance_worst)\n",
        "    return topsis_scores"
      ],
      "metadata": {
        "id": "gX9KSTiDgua_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define weights and impacts for TOPSIS\n",
        "weights = np.array([0.25, 0.25, 0.20, 0.15, 0.15])\n",
        "benefit_criteria = np.array([True, True, True, False, False])  # True: Higher is better, False: Lower is better"
      ],
      "metadata": {
        "id": "TsuVWdWag7mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Track 1st-place finishes for each model\n",
        "model_wins = {model: 0 for model in models}"
      ],
      "metadata": {
        "id": "wegCQZIljZIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models for each text and print rankings\n",
        "for idx, text in enumerate(sample_texts):\n",
        "    print(f\"\\n **Results for Text {idx+1}**\")\n",
        "\n",
        "    reference_summary = dataset[idx][\"highlights\"]\n",
        "    model_results = [evaluate_model_on_text(model, text, reference_summary) for model in models]\n",
        "\n",
        "    decision_matrix = np.array(model_results)\n",
        "    topsis_scores = topsis(decision_matrix, weights, benefit_criteria)\n",
        "\n",
        "    ranked_indices = np.argsort(-topsis_scores)\n",
        "    topsis_ranks = np.zeros_like(ranked_indices)\n",
        "    topsis_ranks[ranked_indices] = np.arange(1, len(models) + 1)\n",
        "\n",
        "    df = pd.DataFrame(model_results, columns=[\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"Inference Time (ms)\", \"Model Size (MB)\"])\n",
        "    df.insert(0, \"Model\", models)\n",
        "    df[\"TOPSIS Score\"] = topsis_scores\n",
        "    df[\"TOPSIS Rank\"] = topsis_ranks\n",
        "\n",
        "    # Count the model with rank 1\n",
        "    best_model = df.loc[df[\"TOPSIS Rank\"] == 1, \"Model\"].values[0]\n",
        "    model_wins[best_model] += 1\n",
        "\n",
        "    print(df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc28Ka0kjE0M",
        "outputId": "a4da996c-929f-4fb8-d513-d17326f94a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **Results for Text 1**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Model  ROUGE-1  ROUGE-2  ROUGE-L  Inference Time (ms)  Model Size (MB)  TOPSIS Score  TOPSIS Rank\n",
            "     facebook/bart-large-cnn 0.441860 0.309524 0.395349         21349.286556      1549.875000      0.777753            1\n",
            "google/pegasus-cnn_dailymail 0.470588 0.337349 0.400000         43114.636660      2177.417969      0.677026            2\n",
            "                    t5-small 0.341463 0.175000 0.341463          6557.838202       230.814453      0.658228            3\n",
            "                     t5-base 0.205128 0.026316 0.153846         20582.642078       850.309570      0.361085            4\n",
            "                    t5-large 0.186667 0.027397 0.133333         67479.874611      2813.980469      0.002241            5\n",
            "\n",
            " **Results for Text 2**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Model  ROUGE-1  ROUGE-2  ROUGE-L  Inference Time (ms)  Model Size (MB)  TOPSIS Score  TOPSIS Rank\n",
            "     facebook/bart-large-cnn 0.488372 0.285714 0.488372         19221.074581      1549.875000      0.783588            1\n",
            "google/pegasus-cnn_dailymail 0.510638 0.282609 0.446809         45635.249853      2177.417969      0.637020            2\n",
            "                    t5-small 0.444444 0.075949 0.271605          5101.004124       230.814453      0.540172            4\n",
            "                     t5-base 0.382979 0.152174 0.319149         21990.037203       850.309570      0.578682            3\n",
            "                    t5-large 0.288889 0.022727 0.177778         67896.852732      2813.980469      0.000000            5\n",
            "\n",
            " **Results for Text 3**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Model  ROUGE-1  ROUGE-2  ROUGE-L  Inference Time (ms)  Model Size (MB)  TOPSIS Score  TOPSIS Rank\n",
            "     facebook/bart-large-cnn 0.348837 0.166667 0.232558         24200.171471      1549.875000      0.555641            2\n",
            "google/pegasus-cnn_dailymail 0.337662 0.133333 0.259740         41813.699484      2177.417969      0.386174            5\n",
            "                    t5-small 0.363636 0.106667 0.259740          8387.832165       230.814453      0.571244            1\n",
            "                     t5-base 0.253521 0.057971 0.197183         25951.577425       850.309570      0.392706            4\n",
            "                    t5-large 0.461538 0.263158 0.333333         75162.184954      2813.980469      0.530087            3\n",
            "\n",
            " **Results for Text 4**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Model  ROUGE-1  ROUGE-2  ROUGE-L  Inference Time (ms)  Model Size (MB)  TOPSIS Score  TOPSIS Rank\n",
            "     facebook/bart-large-cnn 0.395349 0.142857 0.302326         14083.226204      1549.875000      0.721997            2\n",
            "google/pegasus-cnn_dailymail 0.378947 0.129032 0.252632         34725.022078      2177.417969      0.476019            4\n",
            "                    t5-small 0.395349 0.142857 0.255814          5029.531956       230.814453      0.912182            1\n",
            "                     t5-base 0.320988 0.050633 0.197531         14285.638571       850.309570      0.495305            3\n",
            "                    t5-large 0.285714 0.044944 0.219780         43969.032288      2813.980469      0.043721            5\n",
            "\n",
            " **Results for Text 5**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Model  ROUGE-1  ROUGE-2  ROUGE-L  Inference Time (ms)  Model Size (MB)  TOPSIS Score  TOPSIS Rank\n",
            "     facebook/bart-large-cnn 0.543478 0.311111 0.260870         17274.960279      1549.875000      0.728455            2\n",
            "google/pegasus-cnn_dailymail 0.494382 0.206897 0.247191         31916.717291      2177.417969      0.438372            4\n",
            "                    t5-small 0.567901 0.278481 0.271605          5373.928547       230.814453      0.914928            1\n",
            "                     t5-base 0.447059 0.072289 0.282353         16031.247139       850.309570      0.462235            3\n",
            "                    t5-large 0.390244 0.150000 0.243902         50126.765013      2813.980469      0.187743            5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the final winner\n",
        "final_winner = max(model_wins, key=model_wins.get)\n",
        "print(\"\\n Overall Best Model Across All Texts: \", final_winner)\n",
        "print(\"\\n Overall Rankings (Most 1st-Place Wins): \")\n",
        "overall_df = pd.DataFrame(list(model_wins.items()), columns=[\"Model\", \"1st Place Finishes\"]).sort_values(by=\"1st Place Finishes\", ascending=False)\n",
        "print(overall_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvC7DCsnkM0Y",
        "outputId": "bf26a4c6-a5ee-48c5-d82d-6bfb1ddf1561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Overall Best Model Across All Texts:  t5-small\n",
            "\n",
            " Overall Rankings (Most 1st-Place Wins): \n",
            "                       Model  1st Place Finishes\n",
            "                    t5-small                   3\n",
            "     facebook/bart-large-cnn                   2\n",
            "google/pegasus-cnn_dailymail                   0\n",
            "                     t5-base                   0\n",
            "                    t5-large                   0\n"
          ]
        }
      ]
    }
  ]
}